---
title: "iMapPESTS local metabarcoding workflow"
author: "A.M. Piper"
date: "`r Sys.Date()`"
output:
  
  html_document:
    highlighter: null
    theme: "flatly"
    code_download: true
    code_folding: show
    toc: true
    toc_float: 
      collapsed: false
      smooth_scroll: true
    df_print: paged    
  pdf_document: default
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
# Knitr global setup - change eval to true to run code
library(knitr)
knitr::opts_chunk$set(echo = TRUE, eval=FALSE, message=FALSE,error=FALSE, fig.show = "hold", fig.keep = "all")
opts_chunk$set(dev = 'png')
```

# Demultiplex sequencing reads
For this workflow to run, we need to first demultiplex the miseq run again as the miseq does not put indexes in fasta headers by default, and also obtain some necessary files from the sequencing folder. The below code is written for the Agriculture Victoria BASC server, and the locations will be different if you are using a different HPC cluster.

The output directory should be unique for each sequencing run, named as the flowcell id, within a directory called data

For example:

    root/
      ├── data/
         ├── CJL7D/
         
```{bash demultiplex 1 mismatch}
#load module
module load bcl2fastq2/2.20.0-foss-2018b

#raise amount of available file handles
ulimit -n 4000

###Run1

#Set up input and outputs
inputdir=/group/sequencing/210219_M03633_0489_000000000-JDYG3 #CHANGE TO YOUR SEQ RUN
outputdir=/group/pathogens/IAWS/Projects/Metabarcoding/dros_surveillance/data/JDYG3 #CHANGE TO YOUR DATA FOLDER RUN
samplesheet=/group/pathogens/IAWS/Projects/Metabarcoding/dros_surveillance/SampleSheet_JDYG3.csv #CHANGE TO YOUR SAMPLESHEET

# convert samplesheet to unix format
dos2unix $samplesheet

#Demultiplex
bcl2fastq -p 12 --runfolder-dir $inputdir \
--output-dir $outputdir \
--sample-sheet $samplesheet \
--no-lane-splitting --barcode-mismatches 1

# Copy other necessary files and move fastqs
cd $outputdir
cp -r $inputdir/InterOp $outputdir
cp $inputdir/RunInfo.xml $outputdir
cp $inputdir/runParameters.xml $outputdir
cp $samplesheet $outputdir
mv **/*.fastq.gz $outputdir

# Append fcid to start of sample names if missing
fcid=$(echo $inputdir | sed 's/^.*-//')
for i in *.fastq.gz; do
  if ! [[ $i == $fcid* ]]; then
  new=$(echo ${fcid} ${i}) #append together
  new=$(echo ${new// /_}) #remove any whitespace
  mv -v "$i" "$new"
  fi
done

```

# Optional: Run R on BASC
You may wish to run this workflow through the BASC command line in order to take advantage of more processing power. To do this, you can start a new SLURM interactive session. Press the CODE button to the lower right to display the code for this optional step.

```{bash, class.source = 'fold-hide'}
cd /group/pathogens/IAWS/Projects/Metabarcoding/dros_surveillance
# Create new interactive SLURM session
sinteractive --ntasks=1 --cpus-per-task=10 --mem-per-cpu=10GB --time=72:00:00

module load R/4.2.0-foss-2021b
module load pkgconfig/1.5.1-GCCcore-9.3.0-Python-3.8.2
module load GDAL/3.3.0-foss-2021a
module load BLAST+/2.11.0-gompi-2020a
module load Pandoc/2.5

# Load R
R

# Run quit() to quit R once you are finished
```


# Install and load R packages and setup directories {.tabset}

The seqateurs R package also provides wrappers around other software packages for QC. For convenience we will download and install these software in a new folder called "bin"

```{r Manual install} 
#Set required packages
.cran_packages <- c(
  "devtools",
  "ggplot2",
  "gridExtra",
  "data.table",
  "tidyverse", 
  "stringdist",
  "patchwork",
  "vegan",
  "seqinr",
  "patchwork",
  "stringi",
  "phangorn",
  "magrittr",
  "galah"
  )

.bioc_packages <- c(
  "phyloseq",
  "DECIPHER",
  "Biostrings",
  "ShortRead",
  "ggtree",
  "savR",
  "dada2",
  "ngsReports"
  )

.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
  if (!requireNamespace("BiocManager", quietly = TRUE)){
    install.packages("BiocManager")
  }
  BiocManager::install(.bioc_packages[!.inst], ask = F)
}

#Load all published packages
sapply(c(.cran_packages,.bioc_packages), require, character.only = TRUE)

# Install and load github packages
devtools::install_github("alexpiper/seqateurs", dependencies = TRUE)
library(seqateurs)

devtools::install_github("alexpiper/taxreturn", dependencies = TRUE)
library(taxreturn)

devtools::install_github("mikemc/speedyseq", dependencies = TRUE)
library(speedyseq)

#Install bbmap if its not in $path or in bin folder
if(Sys.which("bbduk") == "" & !file.exists("bin/bbmap/bbduk.sh")){
  seqateurs::bbmap_install(dest_dir = "bin")
}

#Install fastqc if its not in $path or in bin folder
if(Sys.which("fastqc") == "" & !file.exists("bin/FastQC/fastqc")){
  seqateurs::fastqc_install(dest_dir = "bin")
}


source("R/dependencies.R")
source("R/functions.R")
source("R/themes.R")
```


# Create sample sheet 

The directory structure should now look something like this:

    root/
    ├── data/
    │   ├── CJL7D/
    │   │  ├── R1.fastq.gz
    │   │  ├── R2.fastq.gz
    │   │  ├── runInfo.xml
    │   │  ├── runParameters.xml
    │   │  ├── SampleSheet.csv
    │   │  └── InterOp/
    │   └── fcid2/
    ├── sample_data/
    ├── reference
    ├── bin
    ├── output/
    └── doc/

The reference and bin folders can be copied from previous runs. 

In order to track samples and relevant QC statistics throughout the metabarcoding pipeline, we will first create a new samplesheet from our input samplesheets. This function requires both the SampleSheet.csv used for the sequencing run, and the runParameters.xml, both of which should have been automatically obtained from the demultiplexed sequencing run folder in the bash step above

```{r create samplesheet}
runs <- dir("data/") #Find all directories within data
SampleSheet <- list.files(paste0("data/", runs), pattern= "SampleSheet", full.names = TRUE)
runParameters <- list.files(paste0("data/", runs), pattern= "[Rr]unParameters.xml", full.names = TRUE)

# Create samplesheet containing samples and run parameters for all runs
samdf <- create_samplesheet(SampleSheet = SampleSheet, runParameters = runParameters, template = "V4") %>%
  distinct()

# Filter out the run where the reverse reads failed
samdf <- samdf %>%
  dplyr::filter(!fcid == "KJ2DL")

# Check if sampleids contain fcid, if not; attatch
samdf <- samdf %>%
  mutate(sample_id = case_when(
    !str_detect(sample_id, fcid) ~ paste0(fcid,"_",sample_id),
    TRUE ~ sample_id
  ))

# Check if samples match samplesheet
fastqFs <- purrr::map(list.dirs("data", recursive=FALSE),
                      list.files, pattern="_R1_", full.names = TRUE) %>%
  unlist() %>%
  str_remove(pattern = "^(.*)\\/") %>%
  str_remove(pattern = "(?:.(?!_S))+$")
fastqFs <- fastqFs[!str_detect(fastqFs, "Undetermined")]

#Check missing in samplesheet
if (length(setdiff(fastqFs, samdf$sample_id)) > 0) {warning("The fastq file/s: ", setdiff(fastqFs, samdf$sample_id), " are not in the sample sheet") }

#Check missing fastqs
if (length(setdiff(samdf$sample_id, fastqFs)) > 0) {
  warning(paste0("The fastq file: ",
                 setdiff(samdf$sample_id, fastqFs),
                 " is missing, dropping from samplesheet \n")) 
  samdf <- samdf %>%
    filter(!sample_id %in% setdiff(samdf$sample_id, fastqFs))
  logdf <- logdf %>%
    filter(!sample_id %in% setdiff(logdf$sample_id, fastqFs))
}

# Add primers to sample sheet
samdf <- samdf %>%
  mutate(pcr_primers = "fwhF2-fwhR2n",
  for_primer_seq = "GGDACWGGWTGAACWGTWTAYCCHCC",
  rev_primer_seq = "GTRATWGCHCCDGCTARWACWGG")

# Params to add in step_add_parameters
params <- tibble(
  pcr_primers = "fwhF2-fwhR2n",
  target_gene="COI",
  phmm = "reference/folmer_fullength_model.rds",
  ref_db = "reference/idtaxa_bftrimmed.rds",
  blast_db = "reference/insecta_hierarchial_bftrimmed.fa.gz",
  exp_length = 205,
  genetic_code = "SGC4",
  coding = TRUE
)

#Write out updated sample CSV for use
write_csv(samdf, "sample_data/Sample_info.csv")
write_csv(params, "sample_data/loci_params.csv")
```

# Load targets package

```{r}
library(targets)
library(tarchetypes)
source("R/functions.R")
```

# Run pipeline
```{r}
tar_make()
```

