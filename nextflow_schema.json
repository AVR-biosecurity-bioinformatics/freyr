{
    "$schema": "https://json-schema.org/draft/2020-12/schema",
    "$id": "https://github.com/AVR-biosecurity-bioinformatics/freyr",
    "title": "AVR-biosecurity-bioinformatics/freyr pipeline parameters",
    "description": "Metabarcoding pipeline [IN DEVELOPMENT]",
    "type": "object",
    "defs": {
        "main_arguments": {
            "title": "Main arguments",
            "type": "object",
            "description": "Main arguments for the pipeline.",
            "required": [ "samplesheet", "loci_params" ],
            "properties": {
                "data_folder": {
                    "type": "string",
                    "format": "directory-path",
                    "pattern": "^\\S+$",
                    "description": "Path to directory/folder containing the input data.",
                    "errorMessage": "Directory must exist and its name cannot contain spaces.",
                    "default": "test_data/dual"
                },
                "refdir": {
                    "type": "string",
                    "format": "directory-path",
                    "pattern": "^\\S+$",
                    "description": "Path to directory/folder containing reference databases.",
                    "errorMessage": "Directory must exist and its name cannot contain spaces.",
                    "default": "reference"
                },
                "samplesheet": {
                    "type": "string",
                    "format": "file-path",
                    "pattern": "^\\S+\\.csv$",
                    "description": "Path to comma-separated file containing the samplesheet.",
                    "errorMessage": "File must exist and be a CSV file with the extension '.csv'.",
                    "schema": "assets/schema_samplesheet.json"
                },
                "loci_params": {
                    "type": "string",
                    "format": "file-path",
                    "pattern": "^\\S+\\.csv$",
                    "description": "Path to comma-separated file containing parameters for each locus or PCR primer pair.",
                    "errorMessage": "File must exist and be a CSV file with the extension '.csv'.",
                    "schema": "assets/schema_loci_params.json"
                },
                "extension": {
                    "type": "string",
                    "pattern": "^[^\\s,]$",
                    "description": "Extension of the FastQ read files, immediately after the digit indicating forward/reverse identity. Used to help match files to samples when explicit read paths are not provided.",
                    "errorMessage": "Read extension must not contain spaces or commas."
                },
                "illumina": {
                    "type": "boolean",
                    "description": "Input is short-read Illumina sequencing data (eg. from MiSeq, NovaSeq).",
                    "errorMessage": "Must be set to 'true' or 'false'.",
                    "default": true
                },
                "pacbio": {
                    "type": "boolean",
                    "description": "Input data is long-read PacBio sequencing data (eg. from REVIO, SEQUEL IIe).",
                    "errorMessage": "Must be set to 'true' or 'false'.",
                    "default": false
                },
                "nanopore": {
                    "type": "boolean",
                    "description": "Input data is long-read Nanopore sequencing data (eg. from MinION, PromethION).",
                    "errorMessage": "Must be set to 'true' or 'false'.",
                    "default": false
                },
                "paired": {
                    "type": "boolean",
                    "description": "Illumina sequencing input data is paired-end.",
                    "errorMessage": "Must be set to 'true' or 'false'.",
                    "default": true
                },
                "high_sensitivity": {
                    "type": "boolean",
                    "description": "Run DADA2 ASV inference in high-sensitivity mode, ie. use pseudo-pooling.",
                    "errorMessage": "Must be set to 'true' or 'false'.",
                    "help_text": "Run DADA2 ASV inference in high-sensitivity mode, ie. use pseudo-pooling.",
                    "default": true
                },
                "primer_n_trim": {
                    "type": "boolean",
                    "description": "Recognise ambiguous bases in reads when trimming primers.",
                    "errorMessage": "Must be set to 'true' or 'false'.",
                    "help_text": "Use 'cutadapt --match-read-wildcards' to recognise N bases in reads when trimming primers. Recommended only for low-quality data input when trying to retain as much data as possible.",
                    "default": false
                },
                "threads": {
                    "type": ["boolean", "integer"],
                    "minimum": 1,
                    "description": "Maximum number of threads/cpus to use. Setting to 'null' will use as many as available.",
                    "errorMessage": "Must be set to an integer >0 or 'null'.",
                    "default": null
                },
                "slurm_account": {
                    "type": "string",
                    "description": "Account to use when submitting SLURM jobs.",
                    "help_text": "Account to use when submitting SLURM jobs.",
                    "default": "default"
                }
            }
        },
        "deugging_options": {
            "title": "Debugging options",
            "type": "object",
            "description": "Arguments that can be used to debug the pipeline; should be used with caution.",
            "properties": {
                "rdata": {
                    "type": "boolean",
                    "description": "Save R environments as an .RData file in each process work directory.",
                    "errorMessage": "Must be set to 'true' or 'false'.",
                    "help_text": "For R-based processes, save the R environments as an .RData file in each process work directory at the successful completion of the process script. Useful for development and debugging, but will increase a run's storage footprint. NOTE: .RData files will not be saved if the R environment exits with an error.",
                    "default": true
                },
                "subsample": {
                    "type": "integer",
                    "minimum": 1,
                    "description": "Randomly reduce the number of input samples to this value.",
                    "errorMessage": "Must be an integer >=1 (or 'null').",
                    "help_text": "Useful to quickly test how the pipeline behaves with a particular dataset. Subsampling is pseudorandom (seed = 1), so should always reproduce the same subset for the same inputs."
                }
            }
        },
        "max_job_request_options": {
            "title": "Max job request options",
            "type": "object",
            "fa_icon": "fab fa-acquisitions-incorporated",
            "description": "Set the top limit for requested resources for any single job.",
            "help_text": "If you are running on a smaller system, a pipeline step requesting more resources than are available may cause the Nextflow to stop the run with an error. These options allow you to cap the maximum resources requested by any single job so that the pipeline will run on your system.\n\nNote that you can not _increase_ the resources requested by any job using these options. For that you will need your own configuration file. See [the nf-core website](https://nf-co.re/usage/configuration) for details.",
            "properties": {
                "max_cpus": {
                    "type": "integer",
                    "description": "Maximum number of CPUs that can be requested for any single job.",
                    "default": 16,
                    "fa_icon": "fas fa-microchip",
                    "help_text": "Use to set an upper-limit for the CPU requirement for each process. Should be an integer e.g. `--max_cpus 1`"
                },
                "max_memory": {
                    "type": "string",
                    "description": "Maximum amount of memory that can be requested for any single job.",
                    "default": "128.GB",
                    "fa_icon": "fas fa-memory",
                    "pattern": "^\\d+(\\.\\d+)?\\.?\\s*(K|M|G|T)?B$",
                    "help_text": "Use to set an upper-limit for the memory requirement for each process. Should be a string in the format integer-unit e.g. `--max_memory '8.GB'`"
                },
                "max_time": {
                    "type": "string",
                    "description": "Maximum amount of time that can be requested for any single job.",
                    "default": "240.h",
                    "fa_icon": "far fa-clock",
                    "pattern": "^(\\d+\\.?\\s*(s|m|h|d|day)\\s*)+$",
                    "help_text": "Use to set an upper-limit for the time requirement for each process. Should be a string in the format integer-unit e.g. `--max_time '2.h'`"
                }
            }
        }
    }
}